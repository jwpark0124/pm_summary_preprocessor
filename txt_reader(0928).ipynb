{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "txt_reader.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dshxpRGKFOQ9",
        "outputId": "78617e59-a565-4b58-ebc8-314885c3f1cd"
      },
      "source": [
        "!pip install hanja"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hanja in /usr/local/lib/python3.7/dist-packages (0.13.3)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from hanja) (3.6.4)\n",
            "Requirement already satisfied: coveralls in /usr/local/lib/python3.7/dist-packages (from hanja) (0.5)\n",
            "Requirement already satisfied: pyyaml==5.1.2 in /usr/local/lib/python3.7/dist-packages (from hanja) (5.1.2)\n",
            "Requirement already satisfied: pytest-cov in /usr/local/lib/python3.7/dist-packages (from hanja) (2.5.1)\n",
            "Requirement already satisfied: coverage<3.999,>=3.6 in /usr/local/lib/python3.7/dist-packages (from coveralls->hanja) (3.7.1)\n",
            "Requirement already satisfied: docopt>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from coveralls->hanja) (0.6.2)\n",
            "Requirement already satisfied: requests>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from coveralls->hanja) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (3.0.4)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (1.10.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (1.15.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (8.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (57.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (21.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKR4Ro1kFYOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e9fdcea-aa88-4c26-aa87-999bbe651d30"
      },
      "source": [
        "import operator\n",
        "from itertools import chain\n",
        "from collections import defaultdict\n",
        "import unicodedata\n",
        "import hanja\n",
        "import argparse\n",
        "from hanja import hangul\n",
        "import pandas as pd\n",
        "import csv\n",
        "import json\n",
        "import re\n",
        "from  pprint import pprint\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from glob import glob\n",
        "import collections"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTHK8XNYle27"
      },
      "source": [
        "sample = sorted(glob(\"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/*.txt\"))\n",
        "# pprint(sample)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyUJOSPEF2vi"
      },
      "source": [
        "# 파일 불러오기\n",
        "\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/284여성(예산결산기금심사)소위01.txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/311법사(법안심사제1)소위01(12.11.15).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/311환노(법안심사)소위01(12.9.17).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/320환노(예산결산기금심사)소위03(13.11.28).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/321교문(예산결산기금심사)소위03(13.12.16).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/321국토(교통법안심사)소위01(13.12.12).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/322국토(민투mrg대책)소위01(14.2.26).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/322국토(철도산업발전)소위01(14.2.7).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/323국토(철도산업발전)소위02(14.4.10).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/320교문(청원심사)소위01(13.11.18).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/346외통(법안심사)소위02(16.10.28.).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/347안행(안전및선거법심사)소위01(16.12.20.).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/354환노(고용노동)소위03(17.9.28.).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/337복지(보육제도개선)소위02(15.11.25).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1차/322국토(민투mrg대책)소위01(14.2.26).txt\"\n",
        "\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/311교과(법안심사)소위03(12.9.24).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/311국토(예산결산기금심사)소위02(12.11.7).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/311법사(예산결산심사)소위03(12.11.21).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/311법사(예산결산심사)소위04(12.12.3).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/311외통(법안심사)소위03(12.11.19).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/311재정(경제재정)소위03(12.9.24).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/311재정(예산결산기금심사)소위03(12.11.6).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/311재정(예산결산기금심사)소위08(12.11.15).txt\"\n",
        "\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/311재정(예산결산기금심사)소위09(12.11.20).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/311행안(법안심사)소위02(12.9.19).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/313문방(법안심사)소위01(13.2.15).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/315국방(예산결산심사)소위01(13.4.23).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/315여성(유엔협약이행정책심사)소위01(13.4.23).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/315국토(교통법안심사)소위01(13.4.23).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/315재정(예산결산기금심사)소위03(13.5.3).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/315재정(조세)소위02(13.4.18).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/315환노(법안심사)소위02(13.4.17)(공청회).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/320국토(청원심사)소위01(13.10.8).txt\"\n",
        "\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/321법사(예산결산심사)소위02(13.12.12).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/324법사(법안심사제2)소위01(14.4.22).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/329법사(법안심사제1)소위01(14.11.6).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/329재정(예산결산기금심사)소위03(14.11.11).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/329환노(법안심사)소위06(14.12.8).txt\"\n",
        "\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/334안행(예산결산기금심사)소위02(15.7.3).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/340국방(법률안심사)소위01(16.2.16).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/346기재(조세)소위08(16.11.28.).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/348법사(법안심사제1)소위01(17.1.18.).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/349국방(법률안심사)소위02(17.2.13.)(공청회).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/337국방(청원심사)소위01(15.11.18).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/340국방(법률안심사)소위01(16.2.16).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/340국방(법률안심사)소위01(16.2.16).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/353기재(조세)소위01(17.8.22.).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/354여성(법안심사)소위01(17.9.18.)(공청회).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/356여성(국제규약점검)소위01(18.2.13.).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/360국토(교통법안심사)소위01(18.5.24.).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/364국토(국토법안심사)소위04(18.12.07.)(공청회).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/364국방(병역특례제도개선)소위02(18.11.29.).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/371환노(예산결산기금심사)소위05(19.11.7.).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/377행안(예산.결산및기금심사)소위01(20.4.28.).txt\"\n",
        "\n",
        "fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/349국방(법률안심사)소위02(17.2.13.)(공청회).txt\"\n",
        "# fname = \"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 1,2차/332법사(법안심사제1)소위02(15.5.1).txt\"\n",
        "\n",
        "# txt= []\n",
        "with open(fname, 'r', encoding='utf-8-sig') as file:\n",
        "  txt = file.readlines()\n",
        "  pass\n",
        "# a = unicodedata.normalize('NFC','金')\n",
        "# b = unicodedata.normalize('NFC',\"樂\")\n",
        "# c = unicodedata.normalize('NFC',\"柳\")\n",
        "# d = unicodedata.normalize('NFC',\"劉\")\n",
        "#     # 같은 한자여도 유니코드가 다를 수 있다. 때문에 하나의 형태의 유니코드로 통일시켜 아래와 같이 적용***\n",
        "#     # 다른 한자로 읽어 들이는 오류를 미리 방지. ex) 金 -> 김, 금 : 한자가 같아도 유니코드가 다르다.\n",
        "#     # ***\n",
        "# for han in range(len(txtt)): \n",
        "#   txttt = txtt[han].replace(\"金\",a).replace(\"金\",a).replace(\"樂\",b).replace(\"樂\",b).replace(\"柳\",c).replace(\"柳\",c).replace(\"劉\",d).replace(\"劉\",d)  \n",
        "#   txt.append(txttt) \n",
        "\n",
        "# pprint(txt)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rQCZl15GUYG"
      },
      "source": [
        "def clean_up(txt):\n",
        "  a = unicodedata.normalize('NFC','金')\n",
        "  b = unicodedata.normalize('NFC',\"樂\")\n",
        "  c = unicodedata.normalize('NFC',\"柳\")\n",
        "  d = unicodedata.normalize('NFC',\"劉\")\n",
        "  tt = []\n",
        "  ttt = []\n",
        "  text = []  \n",
        "  for page in txt:\n",
        "    sent = page.strip().replace(\"金\",a).replace(\"金\",a).replace(\"樂\",b).replace(\"樂\",b).replace(\"柳\",c).replace(\"柳\",c).replace(\"劉\",d).replace(\"劉\",d)        \n",
        "    sent = sent.split(\"\\n\")\n",
        "    tt += sent\n",
        "  for i in range(len(tt)):\n",
        "    if tt[i].endswith(\".\"):            \n",
        "      index = tt[i].rfind('.')\n",
        "      text.append(tt[i][:index] + '. ')\n",
        "    elif tt[i].endswith(\"?\"):            \n",
        "      index = tt[i].rfind('?')\n",
        "      text.append(tt[i][:index] + '? ')\n",
        "    elif tt[i].endswith(\"!\"):            \n",
        "      index = tt[i].rfind('!')\n",
        "      text.append(tt[i][:index] + '! ')\n",
        "    else:\n",
        "      text.append(tt[i])\n",
        "  \n",
        "  return text\n",
        "text = clean_up(txt)\n",
        "# pprint(text)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk3HkJ0cJN69"
      },
      "source": [
        "# yyyymmdd 형태의 날짜 추출\n",
        "def date_extractor(text):\n",
        "  pm_date = ''  \n",
        "  for i in range(7,11):    \n",
        "    if text[i].startswith(\"日\"):      \n",
        "      pm_da = text[i].split(' ')      \n",
        "      pm_dat = pm_da[-1].split(\"年\")            \n",
        "      year = pm_dat[0]\n",
        "      mmdd = pm_dat[1].split(\"(\") \n",
        "      md = mmdd[0]      \n",
        "      for i in range(len(md[1])):\n",
        "        if md[1] == \"月\":\n",
        "          month = \"0\" + md[0]\n",
        "          if md[3] == \"日\":\n",
        "            day = \"0\" + md[2]\n",
        "          elif md [4] == \"日\":\n",
        "            day = md[2] + md[3]\n",
        "        elif md[2] == \"月\":\n",
        "          month = md[0] + md[1]\n",
        "          if md[4] == \"日\":\n",
        "            day = \"0\" + md[3]\n",
        "          elif md [5] == \"日\":\n",
        "            day = md[3] + md[4]\n",
        "      date = year + month + day\n",
        "    elif text[i].startswith(\"일\"):\n",
        "      pm_da = text[i].split(' ')      \n",
        "      pm_dat = pm_da[-1].split(\"년\")            \n",
        "      year = pm_dat[0]\n",
        "      mmdd = pm_dat[1].split(\"(\") \n",
        "      md = mmdd[0]      \n",
        "      for i in range(len(md[1])):\n",
        "        if md[1] == \"월\":\n",
        "          month = \"0\" + md[0]\n",
        "          if md[3] == \"일\":\n",
        "            day = \"0\" + md[2]\n",
        "          elif md [4] == \"일\":\n",
        "            day = md[2] + md[3]\n",
        "        elif md[2] == \"월\":\n",
        "          month = md[0] + md[1]\n",
        "          if md[4] == \"일\":\n",
        "            day = \"0\" + md[3]\n",
        "          elif md [5] == \"일\":\n",
        "            day = md[3] + md[4]\n",
        "      date = year + month + day\n",
        "  return date     \n",
        "pm_date = date_extractor(text)\n",
        "# print(pm_date)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4Ep2-RuJXtP"
      },
      "source": [
        "# 작성자 추출\n",
        "def author(text):\n",
        "  pm_author = ''\n",
        "  for i in range(6,12):\n",
        "    if text[i].startswith('國') and text[i].endswith('處')  or text[i].startswith('국') and text[i].endswith('처'):\n",
        "      pm_author = ''.join(text[i].split(' '))\n",
        "  return pm_author\n",
        "pm_author = author(text)\n",
        "# print(pm_author)"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkbI-UfW7JDa"
      },
      "source": [
        "# 안건\n",
        "def topic_extractor(text):\n",
        "  pm_topi =[]\n",
        "  pm_topic =[]\n",
        "  pm_topict =[]\n",
        "  pm_topicc = []\n",
        "  s_start = False\n",
        "  s_end = False\n",
        "  break_early = False  \n",
        "  for i in range(len(text)):\n",
        "    sent = text[i].strip()\n",
        "    if sent == '상정된 안건' or sent == '審査된案件' or sent == '심사된 안건':\n",
        "      s_start = i    \n",
        "    if sent.endswith('개의)'):\n",
        "      s_end = i - 5\n",
        "      break_early = True\n",
        "      if break_early:\n",
        "        break             \n",
        "  while s_start <= s_end:\n",
        "    s_start += 1\n",
        "    topic = text[s_start].split('\\t')    \n",
        "    topic = hanja.translate(topic[0],\"substitution\")\n",
        "    topic.strip()\n",
        "    pm_top = topic.split('\\n')\n",
        "    pm_topi += pm_top\n",
        "  # if pm_topi[-1].endswith(\")\"):\n",
        "  #   for s in range(len(pm_topi)):\n",
        "  #     if not (pm_topi[s].startswith(\"가\") or pm_topi[s].startswith(\"나\") or pm_topi[s].startswith(\"다\") or pm_topi[s].startswith(\"라\") or pm_topi[s].startswith(\"마\") or pm_topi[s].startswith(\"바\") or pm_topi[s].startswith(\"사\")):\n",
        "  #       pm_topic1 = pm_topi[s] + \" / \"\n",
        "  #       pm_topicc += pm_topic1.split('\\n')\n",
        "  #   pm_topicc[-1] = pm_topicc[-1].replace(\" / \",\"\")    \n",
        "  if len(pm_topi) == 1:\n",
        "    pm_topicc += pm_topi\n",
        "  elif pm_topi[0].startswith(\"1\") and pm_topi[1].startswith(\"2\"):\n",
        "    for s in range(len(pm_topi)):\n",
        "      pm_topic1 = pm_topi[s] + \" / \"\n",
        "      pm_topicc += pm_topic1.split('\\n')\n",
        "    pm_topicc[-1] = pm_topicc[-1].replace(\" / \",\"\")        \n",
        "  else:    \n",
        "    try:      \n",
        "      if type(int(pm_topi[-1][0])) == int:\n",
        "        for n in range(len(pm_topi)-1):      \n",
        "          for m in range(len(pm_topi) -1):        \n",
        "            if pm_topi[n].startswith(\"{}\".format(m)) and pm_topi[n+1].startswith(\"가\"):\n",
        "              pm_topic1 = pm_topi[n] + \" > \"                            \n",
        "              pm_topicc += pm_topic1.split('\\n')\n",
        "            elif pm_topi[n].startswith(\"{}\".format(m)) and not pm_topi[n+1].startswith(\"가\"):\n",
        "              pm_topicc += pm_topi[n] + \" / \"\n",
        "          if pm_topi[n].startswith(\"가\") or pm_topi[n].startswith(\"나\") or pm_topi[n].startswith(\"다\") or pm_topi[n].startswith(\"라\") or pm_topi[n].startswith(\"마\") or pm_topi[n].startswith(\"바\") or pm_topi[n].startswith(\"사\"):\n",
        "              pm_topicc += pm_topi[n].split('\\n')\n",
        "        pm_topicc += pm_topi[-1]\n",
        "    except ValueError:\n",
        "      for n in range(len(pm_topi)):      \n",
        "        for m in range(len(pm_topi)):        \n",
        "          if pm_topi[n].startswith(\"{}\".format(m)) and pm_topi[n+1].startswith(\"가\"):\n",
        "            pm_topic1 = pm_topi[n] + \" > \"\n",
        "            pm_topicc += pm_topic1.split('\\n')      \n",
        "          elif pm_topi[n].startswith(\"{}\".format(m)) and not pm_topi[n+1].startswith(\"가\"):\n",
        "            pm_topicc += pm_topi[n] + \" / \"\n",
        "        if pm_topi[n].startswith(\"가\") or pm_topi[n].startswith(\"나\") or pm_topi[n].startswith(\"다\") or pm_topi[n].startswith(\"라\") or pm_topi[n].startswith(\"마\") or pm_topi[n].startswith(\"바\") or pm_topi[n].startswith(\"사\"):\n",
        "            pm_topicc += pm_topi[n].split('\\n')  \n",
        "  x = range(len(pm_topi))\n",
        "  y = range(1, len(pm_topi))\n",
        "  \n",
        "  for a, b in zip(x, y):   \n",
        "    if pm_topicc[a].startswith(\"가\") and pm_topicc[b].startswith(\"나\"):\n",
        "      pm_topicc[a] = pm_topicc[a] +\", \"      \n",
        "    if pm_topicc[a].startswith(\"나\") and pm_topicc[b].startswith(\"다\"):\n",
        "      pm_topicc[a] = pm_topicc[a] +\", \"\n",
        "    if pm_topicc[a].startswith(\"다\") and pm_topicc[b].startswith(\"라\"):\n",
        "      pm_topicc[a] = pm_topicc[a] +\", \"\n",
        "    if pm_topicc[a].startswith(\"라\") and pm_topicc[b].startswith(\"마\"):\n",
        "      pm_topicc[a] = pm_topicc[a] +\", \"\n",
        "    if pm_topicc[a].startswith(\"마\") and pm_topicc[b].startswith(\"바\"):\n",
        "      pm_topicc[a] = pm_topicc[a] +\", \"\n",
        "    if pm_topicc[a].startswith(\"바\") and pm_topicc[b].startswith(\"사\"):\n",
        "      pm_topicc[a] = pm_topicc[a] +\", \"\n",
        "    if pm_topicc[a].startswith(\"가\") and not pm_topicc[b].startswith(\"나\"):\n",
        "      pm_topicc[a] = pm_topicc[a] + \" / \"  \n",
        "    if pm_topicc[a].startswith(\"나\") and not pm_topicc[b].startswith(\"다\"):\n",
        "      pm_topicc[a] = pm_topicc[a] + \" / \"\n",
        "    if pm_topicc[a].startswith(\"다\") and not pm_topicc[b].startswith(\"라\"):\n",
        "      pm_topicc[a] = pm_topicc[a] + \" / \"\n",
        "    if pm_topicc[a].startswith(\"라\") and not pm_topicc[b].startswith(\"마\"):\n",
        "      pm_topicc[a] = pm_topicc[a] + \" / \"\n",
        "    if pm_topicc[a].startswith(\"마\") and not pm_topicc[b].startswith(\"바\"):\n",
        "      pm_topicc[a] = pm_topicc[a] + \" / \"\n",
        "    if pm_topicc[a].startswith(\"바\") and not pm_topicc[b].startswith(\"사\"):\n",
        "      pm_topicc[a] = pm_topicc[a] + \" / \"\n",
        "    if pm_topicc[a].startswith(\"사\") and not pm_topicc[b].startswith(\"아\"):\n",
        "      pm_topicc[a] = pm_topicc[a] + \" / \"\n",
        "  \n",
        "  for f in range(len(pm_topicc)):\n",
        "    pm_topict += pm_topicc[f].split('\\n')\n",
        "    pm_topic =''.join(pm_topict)\n",
        "  \n",
        "  return pm_topic\n",
        "pm_topic = topic_extractor(text)\n",
        "# pprint(pm_topic)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0qVyTJ-JgLh"
      },
      "source": [
        "# 메타데이터\n",
        "def meta_extractor(text, pm_date, pm_topic, pm_author, fname):\n",
        "    meta = {}\n",
        "    # 카테고리\n",
        "    pm_category = ''\n",
        "    for i in range(3,4):\n",
        "      pm_category += text[i]\n",
        "      pm_cate = pm_category\n",
        "    \n",
        "    pm_category = \"회의록 > 국회소위원회 > \" + pm_cate\n",
        "    meta['카테고리'] = pm_category\n",
        "        \n",
        "    pm_code =''\n",
        "    for i in range(1,6):\n",
        "        pm_code += text[i]\n",
        "        pm_code = pm_code\n",
        "    pm_code = pm_code.replace(\" \",\"\")\n",
        "    meta['회의록코드'] = pm_code\n",
        "    \n",
        "    # 국회명\n",
        "    pm_name_ =\"\"\n",
        "    for i in range(1,3):\n",
        "      pm_name_ += text[i]\n",
        "      pm_name = pm_name_\n",
        "\n",
        "    meta['국회명'] = pm_name\n",
        "\n",
        "    # 회의록 제목\n",
        "    pm_title =''\n",
        "    for i in range(1,6):\n",
        "      if i % 2 == 0:\n",
        "        pm_title += text[i]\n",
        "        pm_title = pm_title\n",
        "      elif i % 2 == 1 and i % 5 != 0: \n",
        "        pm_title += \" \" + text[i]\n",
        "        pm_title = pm_title          \n",
        "      elif i % 5 == 0 :\n",
        "        pm_title += \" \" + text[i].replace(\" \",\"\")\n",
        "        pm_title = pm_title\n",
        "    meta['회의록제목'] = pm_title.replace(\" \",\"\")\n",
        "        \n",
        "    # 작성자    \n",
        "    meta['작성'] = pm_author\n",
        "\n",
        "    # 일시    \n",
        "    meta['일시'] = pm_date\n",
        "\n",
        "    # 토픽    \n",
        "    meta['토픽'] = pm_topic\n",
        "\n",
        "    # 파일명\n",
        "    f_title = ''\n",
        "    f_title = fname.split('/')[-1].split('.txt')[0]\n",
        "    f_title1 = unicodedata.normalize('NFD',f_title)\n",
        "    file_title = unicodedata.normalize('NFC',f_title1)\n",
        "    meta['파일명'] = file_title    \n",
        "    return meta\n",
        "    \n",
        "meta = meta_extractor(text, pm_date, pm_topic, pm_author, fname)\n",
        "# pprint(meta)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Berz-Cj8JtG6"
      },
      "source": [
        "# 본격적 대화(한글버전)\n",
        "def dialog_extractor(txt):\n",
        "  s_start = False\n",
        "  s_end = False\n",
        "  break_early =False  \n",
        "  dialog = []\n",
        "  doc = []   \n",
        "  a = unicodedata.normalize('NFC','金')\n",
        "  b = unicodedata.normalize('NFC',\"樂\")\n",
        "  c = unicodedata.normalize('NFC',\"柳\")  \n",
        "  d = unicodedata.normalize('NFC',\"劉\")\n",
        "   \n",
        "  for i in range(len(txt)):\n",
        "    if txt[i].startswith(\"◯\"):\n",
        "      s_start = i\n",
        "      break_early = True\n",
        "      if break_early:\n",
        "        break \n",
        "  break_early = False\n",
        "  for sid in range(len(txt)):\n",
        "      sent = txt[sid].lstrip().replace(\"金\",a).replace(\"金\",a).replace(\"樂\",b).replace(\"樂\",b).replace(\"柳\",c).replace(\"柳\",c).replace(\"劉\",d).replace(\"劉\",d)\n",
        "      if sent.endswith('산회)\\n') or sent.endswith('중지)\\n'):\n",
        "          s_end = sid \n",
        "  for sid in range(len(txt)):  \n",
        "    if sid >= s_start and sid <= s_end - 1:\n",
        "      sent = txt[sid].replace(\"金\",a).replace(\"金\",a).replace(\"樂\",b).replace(\"樂\",b).replace(\"柳\",c).replace(\"柳\",c).replace(\"劉\",d).replace(\"劉\",d).replace(\"金\",\"김\").replace(\"李\",\"이\").replace(\"梁\",\"양\").replace(\"羅\",\"나\").replace(\"利\",\"이\").replace(\"勞\",\"노\").replace(\"樂\",\"락\").replace(\"盧\",\"노\").replace(\"樂\",\"락\").replace(\"龍\",\"용\").replace(\"沈\",\"심\").replace(\"呂\",\"려\").replace(\"寧\",\"영\").replace(\"宅\",\"택\").replace(\"柳\",\"유\")\n",
        "      sent = hanja.translate(sent,'substitution')\n",
        "      if sent.startswith(\"1.\") or sent.startswith(\"2.\") or sent.startswith(\"3.\") or sent.startswith(\"4.\") or sent.startswith(\"5.\") or sent.startswith(\"가.\") or sent.startswith(\"나.\") or sent.startswith(\"다.\") or sent.startswith(\"라.\"):\n",
        "        continue                \n",
        "      if sent.startswith('◯'):\n",
        "        sent1 = sent.replace('◯','◯ ')          \n",
        "        doc.append(sent1)\n",
        "      else:\n",
        "        doc.append(sent)\n",
        "  doc_q = []\n",
        "  doc_ps =[]\n",
        "  \n",
        "  de = []\n",
        "  for yes in range(len(doc)):\n",
        "    agree = doc[yes].rstrip()    \n",
        "    if agree.endswith(\"음)\"):      \n",
        "      doc[yes-1] += agree.lstrip()\n",
        "      doc_q = ''.join(doc[yes-1].replace('\\n(','$%^(').split('\\n'))                  \n",
        "      doc_ps.append(doc_q)      \n",
        "      \n",
        "    elif agree.startswith(\"(\") and agree.endswith(\")\"):\n",
        "      pass\n",
        "    else:\n",
        "      doc_q = ''.join(doc[yes].replace('\\n','$%^\\n').split('\\n'))              \n",
        "      doc_ps.append(doc_q)\n",
        "  \n",
        "  numb = []\n",
        "  for num in range(len(doc_ps)):\n",
        "    nnu = doc_ps[num]\n",
        "    if nnu.endswith(\"음)\"):\n",
        "      numb.append(num-1)\n",
        "  ddoc = []\n",
        "  for pp in range(len(numb)):\n",
        "    ddoc.append(doc_ps[numb[pp]])\n",
        "\n",
        "\n",
        "  doc_fn = []\n",
        "  for k in range(len(doc_ps)):\n",
        "    if doc_ps[k] not in ddoc:\n",
        "      doc_fn.append(doc_ps[k])\n",
        "  \n",
        "  doc_psddd1 = {}\n",
        "  kkk = []\n",
        "  kk = []\n",
        "  n = 1\n",
        "  for i in range(len(doc_fn)):\n",
        "    if doc_fn[i].startswith(\"◯ \"):\n",
        "      doc_psd ='id{0}# {1}'.format(n,doc_fn[i])\n",
        "      doc_psdd = doc_psd.split(\"# \")\n",
        "      doc_psddd = {doc_psdd[0]:doc_psdd[1]}\n",
        "      # pprint(doc_psddd)\n",
        "      doc_psddd1.update(doc_psddd)  \n",
        "      doc_pst = doc_fn[i].split(\" \")\n",
        "      saram = 'id{0}  ◯ {1} {2}'.format(n,doc_pst[1],doc_pst[2])\n",
        "      n += 1    \n",
        "      saramin = saram.split(\"  \")\n",
        "      saraminga = {saramin[0]:saramin[1]}\n",
        "      kk.append(doc_psddd)             \n",
        "      kkk.append(doc_psddd.values())            \n",
        "    elif doc_fn[i] == \"$%^\":      \n",
        "      pass\n",
        "    elif not (doc_fn[i].startswith(\"◯\") or doc_fn[i].startswith(\"  \")):\n",
        "      pass\n",
        "    else:\n",
        "      doc_psd ='id{0}# {1}'.format(n-1,doc_fn[i])\n",
        "      doc_psdd = doc_psd.split(\"# \")      \n",
        "      doc_psddd = {doc_psdd[0]:doc_psdd[1]}      \n",
        "      r = dict(list(saraminga.items()) + list(doc_psddd.items()) + [(k, saraminga[k] + doc_psddd[k]) for k in set(doc_psddd) & set(saraminga)])      \n",
        "      kk.append(r)             \n",
        "      kkk.append(r.values())  \n",
        "\n",
        "  for i in range(len(kkk)):\n",
        "    dialog += list(kkk[i])\n",
        "  # pprint(kkk)\n",
        "  # pprint(kk)\n",
        "  return dialog\n",
        "dialog = dialog_extractor(txt)\n",
        "# pprint(dialog)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H83kcHalbBzN"
      },
      "source": [
        "# 본격적 대화(원본)\n",
        "def dialog_extractor_or(txt):\n",
        "  s_start = False\n",
        "  s_end = False\n",
        "  break_early =False  \n",
        "  dialog_or = []\n",
        "  doc = []        \n",
        "  a = unicodedata.normalize('NFC','金')\n",
        "  b = unicodedata.normalize('NFC',\"樂\")\n",
        "  c = unicodedata.normalize('NFC',\"柳\")\n",
        "  d = unicodedata.normalize('NFC',\"劉\")    \n",
        "#  柳一鎬\n",
        "#  柳一鎬\n",
        "  for i in range(len(txt)):\n",
        "    if txt[i].startswith(\"◯\"):\n",
        "      s_start = i\n",
        "      break_early = True\n",
        "      if break_early:\n",
        "        break \n",
        "  break_early = False\n",
        "  for sid in range(len(txt)):\n",
        "      sent = txt[sid].lstrip().replace(\"金\",a).replace(\"金\",a).replace(\"樂\",b).replace(\"樂\",b).replace(\"柳\",c).replace(\"柳\",d).replace(\"劉\",d).replace(\"劉\",d)\n",
        "      if sent.endswith('산회)\\n') or sent.endswith('중지)\\n'):\n",
        "          s_end = sid \n",
        "  for sid in range(len(txt)):\n",
        "    if sid >= s_start and sid <= s_end - 1:\n",
        "      sent = txt[sid].replace(\"金\",a).replace(\"金\",a).replace(\"樂\",b).replace(\"樂\",b).replace(\"柳\",c).replace(\"柳\",c).replace(\"劉\",d).replace(\"劉\",d)\n",
        "      if sent.startswith(\"1.\") or sent.startswith(\"2.\") or sent.startswith(\"3.\") or sent.startswith(\"4.\") or sent.startswith(\"5.\") or sent.startswith(\"가.\") or sent.startswith(\"나.\") or sent.startswith(\"다.\") or sent.startswith(\"라.\"):\n",
        "        continue                \n",
        "      if sent.startswith('◯'):        \n",
        "        sent1 = sent.replace('◯','◯ ')          \n",
        "        doc.append(sent1)              \n",
        "      else:\n",
        "        doc.append(sent)\n",
        "    \n",
        "  \n",
        "  doc_q = []\n",
        "  doc_ps =[]\n",
        "  \n",
        "  de = []\n",
        "  for yes in range(len(doc)):\n",
        "    agree = doc[yes].rstrip()    \n",
        "    if agree.endswith(\"음)\"):      \n",
        "      doc[yes-1] += agree.lstrip()\n",
        "      doc_q = ''.join(doc[yes-1].replace('\\n(','$%^(').split('\\n'))                  \n",
        "      doc_ps.append(doc_q)      \n",
        "      \n",
        "    elif agree.startswith(\"(\") and agree.endswith(\")\"):\n",
        "      pass\n",
        "    else:\n",
        "      doc_q = ''.join(doc[yes].replace('\\n','$%^\\n').split('\\n'))              \n",
        "      doc_ps.append(doc_q)\n",
        "  \n",
        "  numb = []\n",
        "  for num in range(len(doc_ps)):\n",
        "    nnu = doc_ps[num]\n",
        "    if nnu.endswith(\"음)\"):\n",
        "      numb.append(num-1)\n",
        "  ddoc = []\n",
        "  for pp in range(len(numb)):\n",
        "    ddoc.append(doc_ps[numb[pp]])\n",
        "\n",
        "\n",
        "  doc_fn = []\n",
        "  for k in range(len(doc_ps)):\n",
        "    if doc_ps[k] not in ddoc:\n",
        "      doc_fn.append(doc_ps[k])\n",
        "  \n",
        "  doc_psddd1 = {}\n",
        "  kkk = []\n",
        "  kk = []\n",
        "  n = 1\n",
        "  for i in range(len(doc_fn)):\n",
        "    if doc_fn[i].startswith(\"◯ \"):\n",
        "      doc_psd ='id{0}# {1}'.format(n,doc_fn[i])\n",
        "      doc_psdd = doc_psd.split(\"# \")\n",
        "      doc_psddd = {doc_psdd[0]:doc_psdd[1]}\n",
        "      # pprint(doc_psddd)\n",
        "      doc_psddd1.update(doc_psddd)  \n",
        "      doc_pst = doc_fn[i].split(\" \")\n",
        "      saram = 'id{0}  ◯ {1} {2}'.format(n,doc_pst[1],doc_pst[2])\n",
        "      n += 1    \n",
        "      saramin = saram.split(\"  \")\n",
        "      saraminga = {saramin[0]:saramin[1]}\n",
        "      kk.append(doc_psddd)             \n",
        "      kkk.append(doc_psddd.values())            \n",
        "    elif doc_fn[i] == \"$%^\":      \n",
        "      pass\n",
        "    elif not (doc_fn[i].startswith(\"◯\") or doc_fn[i].startswith(\"  \")):\n",
        "      pass\n",
        "    else:\n",
        "      doc_psd ='id{0}# {1}'.format(n-1,doc_fn[i])\n",
        "      doc_psdd = doc_psd.split(\"# \")      \n",
        "      doc_psddd = {doc_psdd[0]:doc_psdd[1]}      \n",
        "      r = dict(list(saraminga.items()) + list(doc_psddd.items()) + [(k, saraminga[k] + doc_psddd[k]) for k in set(doc_psddd) & set(saraminga)])      \n",
        "      kk.append(r)             \n",
        "      kkk.append(r.values())\n",
        "  # pprint(kk)\n",
        "  # print(kkk)\n",
        "  for i in range(len(kkk)):\n",
        "    dialog_or += list(kkk[i])\n",
        "  # print(dialog_or)\n",
        "  return dialog_or\n",
        "dialog_or = dialog_extractor_or(txt)\n",
        "# pprint(dialog_or)  "
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co0afO_U_ayL"
      },
      "source": [
        "def mapping(txt):\n",
        "  s_start = False\n",
        "  s_end = False\n",
        "  break_early =False  \n",
        "  mapping = []\n",
        "  doc = []        \n",
        "  n_id =[]\n",
        "  o_id = [] \n",
        "  o_utter = []\n",
        "  n_utter = []\n",
        "  a = unicodedata.normalize('NFC','金')\n",
        "  b = unicodedata.normalize('NFC',\"樂\")\n",
        "  c = unicodedata.normalize('NFC',\"柳\")\n",
        "  d = unicodedata.normalize('NFC',\"劉\")    \n",
        "#  柳一鎬\n",
        "#  柳一鎬\n",
        "  for i in range(len(txt)):\n",
        "    if txt[i].startswith(\"◯\"):\n",
        "      s_start = i\n",
        "      break_early = True\n",
        "      if break_early:\n",
        "        break \n",
        "  break_early = False\n",
        "  for sid in range(len(txt)):\n",
        "      sent = txt[sid].lstrip().replace(\"金\",a).replace(\"金\",a).replace(\"樂\",b).replace(\"樂\",b).replace(\"柳\",c).replace(\"柳\",d).replace(\"劉\",d).replace(\"劉\",d)\n",
        "      if sent.endswith('산회)\\n') or sent.endswith('중지)\\n'):\n",
        "          s_end = sid \n",
        "  for sid in range(len(txt)):\n",
        "    if sid >= s_start and sid <= s_end - 1:\n",
        "      sent = txt[sid].replace(\"金\",a).replace(\"金\",a).replace(\"樂\",b).replace(\"樂\",b).replace(\"柳\",c).replace(\"柳\",c).replace(\"劉\",d).replace(\"劉\",d)\n",
        "      if sent.startswith(\"1.\") or sent.startswith(\"2.\") or sent.startswith(\"3.\") or sent.startswith(\"4.\") or sent.startswith(\"5.\") or sent.startswith(\"가.\") or sent.startswith(\"나.\") or sent.startswith(\"다.\") or sent.startswith(\"라.\"):\n",
        "        continue                \n",
        "      if sent.startswith('◯'):        \n",
        "        sent1 = sent.replace('◯','◯ ')          \n",
        "        doc.append(sent1)              \n",
        "      else:\n",
        "        doc.append(sent)\n",
        "    \n",
        "  \n",
        "  doc_q = []\n",
        "  doc_ps =[]\n",
        "  \n",
        "  de = []\n",
        "  for yes in range(len(doc)):\n",
        "    agree = doc[yes].rstrip()    \n",
        "    if agree.endswith(\"음)\"):      \n",
        "      doc[yes-1] += agree.lstrip()\n",
        "      doc_q = ''.join(doc[yes-1].replace('\\n(','$%^(').split('\\n'))                  \n",
        "      doc_ps.append(doc_q)      \n",
        "      \n",
        "    elif agree.startswith(\"(\") and agree.endswith(\")\"):\n",
        "      pass\n",
        "    else:\n",
        "      doc_q = ''.join(doc[yes].replace('\\n','$%^\\n').split('\\n'))              \n",
        "      doc_ps.append(doc_q)\n",
        "  \n",
        "  numb = []\n",
        "  for num in range(len(doc_ps)):\n",
        "    nnu = doc_ps[num]\n",
        "    if nnu.endswith(\"음)\"):\n",
        "      numb.append(num-1)\n",
        "  ddoc = []\n",
        "  for pp in range(len(numb)):\n",
        "    ddoc.append(doc_ps[numb[pp]])\n",
        "\n",
        "  doc_fn = []\n",
        "  for k in range(len(doc_ps)):\n",
        "    if doc_ps[k] not in ddoc:\n",
        "      doc_fn.append(doc_ps[k])  \n",
        "  doc_psddd1 = {}\n",
        "  kkk = []\n",
        "  \n",
        "  n = 1\n",
        "  for i in range(len(doc_fn)):\n",
        "    if doc_fn[i].startswith(\"◯ \"):\n",
        "      doc_psd ='o_id.{0}# {1}'.format(n,doc_fn[i])\n",
        "      doc_psdd = doc_psd.split(\"# \")\n",
        "      doc_psddd = {doc_psdd[0]:doc_psdd[1]}\n",
        "      o_id.append(doc_psdd[0])\n",
        "      o_utter.append(doc_psdd[1])\n",
        "      doc_psddd1.update(doc_psddd)  \n",
        "      doc_pst = doc_fn[i].split(\" \")\n",
        "      saram = 'o_id.{0}  ◯ {1} {2}'.format(n,doc_pst[1],doc_pst[2])\n",
        "      n += 1    \n",
        "      saramin = saram.split(\"  \")\n",
        "      saraminga = {saramin[0]:saramin[1]}      \n",
        "      kkk.append(doc_psddd.values())            \n",
        "      \n",
        "    elif doc_fn[i] == \"$%^\":      \n",
        "      # print(doc_fn[i])\n",
        "      pass\n",
        "    elif not (doc_fn[i].startswith(\"◯\") or doc_fn[i].startswith(\"  \")):\n",
        "      pass\n",
        "    else:\n",
        "      doc_psd ='o_id.{0}# {1}'.format(n-1,doc_fn[i])\n",
        "      doc_psdd = doc_psd.split(\"# \")      \n",
        "      doc_psddd = {doc_psdd[0]:doc_psdd[1]}\n",
        "      o_id.append(doc_psdd[0])\n",
        "      o_utter.append(doc_psdd[1])     \n",
        "      r = dict(list(saraminga.items()) + list(doc_psddd.items()) + [(k, saraminga[k] + doc_psddd[k]) for k in set(doc_psddd) & set(saraminga)])      \n",
        "      # o_id.append(list(r.keys()))          \n",
        "      kkk.append(r.values())  \n",
        "\n",
        "  # pprint(o_utter)\n",
        "  \n",
        "  \n",
        "  m=1  \n",
        "  for j in range(len(doc_fn)):\n",
        "    if doc_fn[j] == \"$%^\":         \n",
        "      pass\n",
        "    elif not (doc_fn[j].startswith(\"◯\") or doc_fn[j].startswith(\"  \")):\n",
        "      pass\n",
        "    else:      \n",
        "      doc_psd ='n_id.{0}# {1}'.format(m,doc_fn[j])\n",
        "      m += 1\n",
        "      doc_psdd = doc_psd.split(\"# \")\n",
        "      doc_psdddd = {doc_psdd[0]:doc_psdd[1]}      \n",
        "      # tot(doc_psdd[0]) = doc_psddds\n",
        "      # tot[str(doc_psdddd.keys())] = doc_psddd\n",
        "      n_id.append(doc_psdd[0])\n",
        "      n_utter.append(doc_psdd[1])\n",
        "  # pprint(n_utter)\n",
        "  # pprint(o_id)\n",
        "  for i in range(len(kkk)):\n",
        "    mapping += list(kkk[i])\n",
        "  # pprint(mapping)  \n",
        "\n",
        "  return o_id, n_id, o_utter, n_utter\n",
        "map = mapping(txt)\n",
        "# print(map)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w54Mm97_Kj27"
      },
      "source": [
        "# 대화에 참여자 이름, 직위(한글화)\n",
        "def speaker_extractor(dialog):\n",
        "  global persons\n",
        "  persons =[]\n",
        "  occups = []\n",
        "  speaker_ex = []\n",
        "  for i in range(len(dialog)):\n",
        "    dialog_s = dialog[i].split(' ')    \n",
        "    first_t = dialog_s[1]\n",
        "    second_t = dialog_s[2]\n",
        "    # print(dialog_s)\n",
        "    # if first_t.endswith(\"관\") or first_t.endswith(\"장\") or first_t.endswith(\"위원\") or first_t.endswith(\"참고인\") and len(first_t) >= 3:\n",
        "    if second_t != \"의원\" and second_t != \"위원\" and second_t != \"委員\" and second_t != \"議員\":\n",
        "      occup = first_t.replace(\"◯ \",\"\")\n",
        "    else:\n",
        "      person = first_t.replace(\"◯ \",\"\")\n",
        "    if second_t == \"의원\" or second_t == \"위원\" or second_t == \"委員\" or second_t == \"議員\":\n",
        "      occup = second_t\n",
        "    else:\n",
        "      person = second_t    \n",
        "    \n",
        "    persons.append(person)\n",
        "    occups.append(occup)   \n",
        "  po = []\n",
        "  for j in range(len(persons)):\n",
        "    sp = persons[j]+ \" \" + occups[j]\n",
        "    po.append(sp)\n",
        "  \n",
        "    \n",
        "  n_po = []\n",
        "  for v in po:\n",
        "    if v not in n_po:\n",
        "      n_po.append(v)    \n",
        "  for w in range(len(n_po)):\n",
        "    n_pos = n_po[w].split(' ') \n",
        "    speaker_ex.append(n_pos)        \n",
        "  return speaker_ex \n",
        "speaker_ex = speaker_extractor(dialog)\n",
        "# pprint(speaker_ex)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlxTT9JN86m_"
      },
      "source": [
        "# 대화에 참여자 이름, 직위\n",
        "def speaker_extractor_or(dialog_or): \n",
        "  global personss\n",
        "  personss =[]\n",
        "  occups = []\n",
        "  speaker_ex_or = []\n",
        "  for i in range(len(dialog_or)):\n",
        "    dialog_s = dialog_or[i].split(' ')    \n",
        "    first_t = dialog_s[1]\n",
        "    second_t = dialog_s[2]    \n",
        "    # if first_t.endswith(\"관\") or first_t.endswith(\"장\") or first_t.endswith(\"위원\") or first_t.endswith(\"참고인\") and len(first_t) >= 3:\n",
        "    if second_t != \"의원\" and second_t != \"위원\" and second_t != \"委員\" and second_t != \"議員\":\n",
        "      occup = first_t.replace(\"◯ \",\"\")\n",
        "    else:\n",
        "      person = first_t.replace(\"◯ \",\"\")\n",
        "    if second_t == \"의원\" or second_t == \"위원\" or second_t == \"委員\" or second_t == \"議員\":\n",
        "      occup = second_t\n",
        "    else:\n",
        "      person = second_t        \n",
        "    personss.append(person)\n",
        "    occups.append(occup)  \n",
        "  po = []\n",
        "  for j in range(len(personss)):\n",
        "    sp = personss[j]+ \" \" + occups[j]\n",
        "    po.append(sp)\n",
        "  # pprint(po)\n",
        "  n_po = []\n",
        "\n",
        "  for v in po:\n",
        "    if v not in n_po:\n",
        "      n_po.append(v)      \n",
        "  for w in range(len(n_po)):    \n",
        "    n_pos = n_po[w].split(' ')    \n",
        "    speaker_ex_or.append(n_pos) \n",
        "  return speaker_ex_or\n",
        "speaker_ex_or = speaker_extractor_or(dialog_or)\n",
        "\n",
        "# pprint(speaker_ex_or)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNIjgTfeXewY"
      },
      "source": [
        "# 발언자, 발언(한글수정)\n",
        "def utterance_extractor(dialog): \n",
        "  utterance_id = []\n",
        "  utterance_form = []  \n",
        "  utterance_note = []\n",
        "  \n",
        "  for i in range(len(dialog)):\n",
        "    dialog_m = dialog[i].split('$%^')\n",
        "    dialog_s = dialog_m[0].split(' ')\n",
        "    first_s = dialog_s[1:3]\n",
        "    second_s = dialog_s[4:]\n",
        "    utter_id = ' '.join(first_s)\n",
        "    utter = ' '.join(second_s)    \n",
        "    third_s = dialog_m[-1]\n",
        "    utterance_id.append(utter_id)      \n",
        "    utterance_form.append(utter)  \n",
        "    utterance_note.append(third_s)\n",
        "  \n",
        "  return persons,utterance_id, utterance_form, utterance_note\n",
        "utterance_ex = utterance_extractor(dialog)\n",
        "# pprint(utterance_ex)"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRfUrnacumJR"
      },
      "source": [
        "# 발언자, 발언(원본)\n",
        "def utterance_extractor_or(dialog_or): \n",
        "  utterance_id = []\n",
        "  utterance_form = []\n",
        "  utterance_note = []\n",
        "\n",
        "  for i in range(len(dialog_or)):\n",
        "    dialog_m = dialog_or[i].split('$%^')\n",
        "    dialog_s = dialog_m[0].split(' ')    \n",
        "    second_s = dialog_s[4:]    \n",
        "    utter = ' '.join(second_s)\n",
        "    third_s = dialog_m[-1]\n",
        "    utterance_form.append(utter)\n",
        "    utterance_note.append(third_s)\n",
        "  return personss, utterance_form, utterance_note\n",
        "utterance_ex_or = utterance_extractor_or(dialog_or)\n",
        "# pprint(utterance_ex_or)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJJro59bvAC8"
      },
      "source": [
        "# utterance info\n",
        "def dialog_formatting(utterance_ex, utterance_ex_or):  \n",
        "  dialog_json = []    \n",
        "  utterance_id = utterance_ex_or[0]\n",
        "  utterance_form = utterance_ex[1]\n",
        "  utterance_form_or = utterance_ex_or[1]\n",
        "  utterace_note = utterance_ex_or[2]\n",
        "  # pprint(utterance_form_or)\n",
        "  for i in range(len(utterance_ex_or[0])):\n",
        "    d = {}\n",
        "    d['speaker'] = utterance_id[i]\n",
        "    d['utterance'] = utterance_form[i].rstrip()\n",
        "    d['utterance_or'] = utterance_form_or[i].rstrip()   \n",
        "    d['note'] = utterace_note[i].rstrip()\n",
        "    dialog_json.append(d)      \n",
        "  # result.append(d)\n",
        "  return dialog_json\n",
        "  \n",
        "dialog_json = dialog_formatting(utterance_ex, utterance_ex_or)\n",
        "# pprint(dialog_json)"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqok_ALFLX-1"
      },
      "source": [
        " # speaker info\n",
        "def speaker_list_extractor(speaker_ex,speaker_ex_or):\n",
        "  global p_name\n",
        "  p_name = []  \n",
        "  speaker_list = []  \n",
        "    \n",
        "  for i in range(len(speaker_ex)):        \n",
        "    name = speaker_ex[i][0]        \n",
        "    position = speaker_ex[i][1] \n",
        "    # o_name = speaker_ex_or[i][0]\n",
        "    if position == \"진술인\" or position == \"참고인\":\n",
        "      pass\n",
        "    elif position != \"소위원장대리\":\n",
        "      d = {}      \n",
        "      d['id'] = name\n",
        "      # d['age'] = \"NA\"\n",
        "      d['occupation'] = position\n",
        "      # d['sex'] = \"NA\"\n",
        "      # d['birthplace'] = \"NA\"\n",
        "      # d['principal_residence'] = \"NA\"\n",
        "      # d['current_residence'] = \"NA\"\n",
        "      # d['original_speaker_id'] = o_name \n",
        "      speaker_list.append(d) \n",
        "      p_name.append(d['id']) \n",
        "    \n",
        "  return speaker_list\n",
        "speaker_list = speaker_list_extractor(speaker_ex,speaker_ex_or)\n",
        "# pprint(speaker_list)"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPqwbRm6mP82"
      },
      "source": [
        "# speaker info(original)\n",
        "def speaker_list_extractor_or(speaker_ex,speaker_ex_or):\n",
        "  global p2_name\n",
        "  p2_name = []  \n",
        "  speaker_list = []         \n",
        "  for i in range(len(speaker_ex_or)):        \n",
        "    # name = speaker_ex[i][0]        \n",
        "    position = speaker_ex[i][1] \n",
        "    o_name = speaker_ex_or[i][0]\n",
        "    # print(o_name)\n",
        "    if position == \"진술인\" or position == \"참고인\":\n",
        "      pass\n",
        "    elif position != \"소위원장대리\":\n",
        "      d = {}      \n",
        "      d['id'] = o_name\n",
        "      # d['age'] = \"NA\"\n",
        "      d['occupation'] = position\n",
        "      # d['sex'] = \"NA\"\n",
        "      # d['birthplace'] = \"NA\"\n",
        "      # d['principal_residence'] = \"NA\"\n",
        "      # d['current_residence'] = \"NA\"\n",
        "      # d['original_speaker_id'] = o_name \n",
        "      speaker_list.append(d)\n",
        "      p2_name.append(d['id'])\n",
        "  return speaker_list\n",
        "speaker_list__ = speaker_list_extractor_or(speaker_ex,speaker_ex_or)\n",
        "# pprint(speaker_list__)"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGLh485LmDN-"
      },
      "source": [
        " def speaker_extractor2_or(text,speaker_list, speaker_list__, speaker_ex):\n",
        "  s_start = False  \n",
        "  ss_start = False  \n",
        "  break_early = False\n",
        "  s_sentence = []  \n",
        "  ss_sentence = []  \n",
        "  sss_sentence =[]\n",
        "  c_sentence = []\n",
        "  d_sentence = []\n",
        "  speaker_list2 = []  \n",
        "  speaker_list2__2 = []    \n",
        "  e_sentence = []\n",
        "  f_sentence = []\n",
        "  g_sentence = []\n",
        "  h_sentence = []\n",
        "  B_member = []\n",
        "  part2 = False\n",
        "  part3 = False\n",
        "  part4 = False\n",
        "  part5 = False  \n",
        "  c_end = False\n",
        "  d_end = False\n",
        "  e_end = False\n",
        "  f_end = False\n",
        "  g_end = False\n",
        "  h_end = False\n",
        "  role = []\n",
        "  b = 0\n",
        "  # 산회) 이하 제~일) 이상 문장 뽑기\n",
        "  # for i in range(len(text)):\n",
        "  #   if text[i].endswith(\"산회)\") or text[i].endswith('중지)'):\n",
        "  #     s_start = i + 1  \n",
        "  for i in range(len(text)):\n",
        "    if text[i].startswith(\"◯출석\") or text[i].startswith(\"○출석\"):\n",
        "      s_start = i - 1       \n",
        "      break_early = True\n",
        "      break \n",
        "  break_early = False  \n",
        "  for i in range(len(text)):\n",
        "    if text[i].startswith(\"제\") and (text[i].endswith('일)') or text[i].endswith('차')):\n",
        "      if text[i - 1] == '' and text[i-2] == '' and text[i-3] =='':\n",
        "        s_end = i - 3\n",
        "        break_early = True\n",
        "        break\n",
        "      break_early = False\n",
        "      if text[i - 1] == '' and text[i-2] == '':\n",
        "        s_end = i - 2\n",
        "        break_early = True\n",
        "        break\n",
        "      break_early = False\n",
        "      if text[i - 1] != '':\n",
        "        s_end = i\n",
        "        break_early = True\n",
        "        break\n",
        "      break_early = False  \n",
        "  for sid in range(len(text)):    \n",
        "    if sid >=s_start and sid < s_end:      \n",
        "      sub_sentences = hanja.translate(text[sid],\"substitution\").replace(\"金\",\"김\").replace(\"李\",\"이\").replace(\"梁\",\"양\").replace(\"羅\",\"나\").replace(\"利\",\"이\").replace(\"勞\",\"노\").replace(\"樂\",\"락\").replace(\"盧\",\"노\").replace(\"樂\",\"락\").replace(\"龍\",\"용\").replace(\"沈\",\"심\").replace(\"宅\",\"택\").replace(\"柳\",\"유\")\n",
        "      s_sentence.append(sub_sentences)   \n",
        "\n",
        "  # 출석 위원\n",
        "  for j in range(len(s_sentence)):    \n",
        "    if s_sentence[j].startswith(\"◯\") or s_sentence[j].startswith(\"○\"):\n",
        "      m =  j + 1\n",
        "      A_member = s_sentence[m].split(\"  \")      \n",
        "      break_early = True\n",
        "      break\n",
        "  break_early = False   \n",
        "  # p_name2 = []  \n",
        "  for t in range(len(A_member)):    \n",
        "    if A_member[t] not in p_name:      \n",
        "      name = A_member[t]\n",
        "      d = {}      \n",
        "      d['id'] = name\n",
        "      # d['age'] = \"NA\"\n",
        "      d['occupation'] = \"위원\"\n",
        "      # d['sex'] = \"NA\"\n",
        "      # d['birthplace'] = \"NA\"\n",
        "      # d['principal_residence'] = \"NA\"\n",
        "      # d['current_residence'] = \"NA\"\n",
        "      # d['original_speaker_id'] = name \n",
        "      speaker_list2.append(d)  \n",
        "  \n",
        "  for u in range(len(s_sentence)):\n",
        "    if s_sentence[u] == \"\" and s_sentence[u+1] ==\"\":\n",
        "      first_line_end = u      \n",
        "      break_early = True\n",
        "      break \n",
        "  break_early = False \n",
        "    \n",
        "  # 위원 아닌 출석 의원(X인)\n",
        "  for e in range(len(s_sentence)):\n",
        "    if e > m and e < first_line_end:\n",
        "      ss_sentence += s_sentence[e].split(\"\\n\")      \n",
        "  for a in range(len(ss_sentence)):    \n",
        "    # 수정했는데 맞겠지?\n",
        "    if (ss_sentence[a].startswith(\"◯\") or ss_sentence[a].startswith(\"○\")) and ss_sentence[a].endswith(\"인)\"):      \n",
        "      if ss_sentence[a].startswith(\"◯위원\") or ss_sentence[a].startswith(\"○위원\"):                \n",
        "        b = a + 1        \n",
        "        B_member = ss_sentence[b].split('  ')\n",
        "        occup = \"의원\"\n",
        "        break       \n",
        "      else:\n",
        "        b = a + 1\n",
        "        B_member = ss_sentence[b].split('  ') \n",
        "        occup = \"위원\"\n",
        "        break     \n",
        "  for y in range(len(B_member)): \n",
        "    if B_member[y] not in p_name:\n",
        "      name = B_member[y]\n",
        "      d = {}      \n",
        "      d['id'] = name\n",
        "      # d['age'] = \"NA\"\n",
        "      d['occupation'] = occup\n",
        "      # d['sex'] = \"NA\"\n",
        "      # d['birthplace'] = \"NA\"\n",
        "      # d['principal_residence'] = \"NA\"\n",
        "      # d['current_residence'] = \"NA\"\n",
        "      # d['original_speaker_id'] = name \n",
        "      speaker_list2.append(d)\n",
        "  # 위원 아닌 출석 의원(X인)2\n",
        "  if ss_sentence[b+1].endswith(\"인)\") == True:\n",
        "    for e in range(len(s_sentence)):\n",
        "      if e > m and e < first_line_end:\n",
        "        ss_sentence += s_sentence[e].split(\"\\n\")      \n",
        "    for a in range(len(ss_sentence)):    \n",
        "      # 수정했는데 맞겠지?\n",
        "      if (ss_sentence[a].startswith(\"◯\") or ss_sentence[a].startswith(\"○\")) and ss_sentence[a].endswith(\"인)\"):      \n",
        "        if ss_sentence[a].startswith(\"◯위원\") or ss_sentence[a].startswith(\"○위원\"):                \n",
        "          b = a + 1        \n",
        "          B_member = ss_sentence[b].split('  ')\n",
        "          occup = \"의원\"\n",
        "        else:\n",
        "          b = a + 1\n",
        "          B_member = ss_sentence[b].split('  ') \n",
        "          occup = \"위원\"\n",
        "          \n",
        "    for y in range(len(B_member)): \n",
        "      if B_member[y] not in p_name:\n",
        "        name = B_member[y]\n",
        "        d = {}      \n",
        "        d['id'] = name\n",
        "        # d['age'] = \"NA\"\n",
        "        d['occupation'] = occup\n",
        "        # d['sex'] = \"NA\"\n",
        "        # d['birthplace'] = \"NA\"\n",
        "        # d['principal_residence'] = \"NA\"\n",
        "        # d['current_residence'] = \"NA\"\n",
        "        # d['original_speaker_id'] = name \n",
        "        speaker_list2.append(d)\n",
        "  \n",
        "  # 출석 전문위원\n",
        "  for a in range(len(ss_sentence)):    \n",
        "    if not ss_sentence[a].endswith(\"인)\") and (ss_sentence[a].startswith(\"◯\") or ss_sentence[a].startswith(\"○\")):\n",
        "      s_start = a+1  \n",
        "  for z in range(len(ss_sentence)):\n",
        "    if z >= s_start:\n",
        "      sss = ss_sentence[z].split(\"\\n\")\n",
        "      sss_sentence += sss    \n",
        "  count = int(len(sss_sentence) / 2)  \n",
        "  id_s = range(count,len(sss_sentence))  \n",
        "  ocu_s = range(0,count)\n",
        "  for n, m in zip(id_s, ocu_s) :                \n",
        "    if sss_sentence[n] not in p_name:        \n",
        "      d = {}\n",
        "      d['id'] = sss_sentence[n]\n",
        "      # d['age'] = \"NA\"\n",
        "      d['occupation'] = sss_sentence[m]\n",
        "      # d['sex'] = \"NA\"\n",
        "      # d['birthplace'] = \"NA\"\n",
        "      # d['principal_residence'] = \"NA\"\n",
        "      # d['current_residence'] = \"NA\"\n",
        "      # d['original_speaker_id'] = sss_sentence[n] \n",
        "      speaker_list2.append(d) \n",
        "  \n",
        "  try:  \n",
        "    ## 위원 의원 아래 참석자      \n",
        "    for p in range(len(s_sentence)):        \n",
        "      if s_sentence[p].startswith(\"◯\") and s_sentence[p].endswith(\"참석자\"):      \n",
        "        part = p + 1\n",
        "        c = p + 2\n",
        "        c_part = s_sentence[part]\n",
        "        break  \n",
        "    for l in range(len(s_sentence)):    \n",
        "      if l >= part:      \n",
        "        if s_sentence[l] == \"\" and s_sentence[l+1] ==\"\":\n",
        "          c_end = l\n",
        "          break\n",
        "        else:\n",
        "          c_end = l + 1\n",
        "    for m in range(len(s_sentence)):\n",
        "      if m >= part and m < c_end:\n",
        "        ssss = s_sentence[m].split('\\n')      \n",
        "        c_sentence += ssss\n",
        "    count = int((len(c_sentence) -1) / 2) + 1  \n",
        "    id_c = range(count, len(c_sentence))\n",
        "    ocu_c = range(1,count)\n",
        "    for n, m in zip(id_c, ocu_c) :                \n",
        "      if c_sentence[n] not in p_name:        \n",
        "        d = {}\n",
        "        d['id'] = c_sentence[n]\n",
        "        # d['age'] = \"NA\"\n",
        "        d['occupation'] = c_part + c_sentence[m]\n",
        "        # d['sex'] = \"NA\"\n",
        "        # d['birthplace'] = \"NA\"\n",
        "        # d['principal_residence'] = \"NA\"\n",
        "        # d['current_residence'] = \"NA\"\n",
        "        # d['original_speaker_id'] = c_sentence[n]\n",
        "        speaker_list2.append(d)\n",
        "\n",
        "  # 그다음꺼 있으면    \n",
        "    if c_end != False:\n",
        "      for h in range(len(s_sentence)):\n",
        "        if h > c_end:\n",
        "          if s_sentence[c_end] ==\"\" and s_sentence[c_end+1] ==\"\" and not s_sentence[c_end+2].startswith(\"◯\"):          \n",
        "            part2 = c_end +2\n",
        "            d_part = s_sentence[part2]\n",
        "            break\n",
        "      if part2 != False:\n",
        "        for r in range(len(s_sentence)):\n",
        "          if r >= part2:\n",
        "            if s_sentence[r] == \"\" and s_sentence[r+1] ==\"\":\n",
        "              d_end = r        \n",
        "              break\n",
        "            else:\n",
        "              d_end = r + 1\n",
        "      if part2 != False:\n",
        "        for m in range(len(s_sentence)):\n",
        "          if m >= part2 and m < d_end:\n",
        "            sss = s_sentence[m].split('\\n')      \n",
        "            d_sentence += sss\n",
        "        count = int((len(d_sentence) -1) / 2) + 1  \n",
        "        id_d = range(count, len(d_sentence))\n",
        "        ocu_d = range(1,count)\n",
        "        for n, m in zip(id_d, ocu_d) :                \n",
        "          if d_sentence[n] not in p_name:        \n",
        "            d = {}\n",
        "            d['id'] = d_sentence[n]\n",
        "            # d['age'] = \"NA\"\n",
        "            d['occupation'] = d_part + d_sentence[m]\n",
        "            # d['sex'] = \"NA\"\n",
        "            # d['birthplace'] = \"NA\"\n",
        "            # d['principal_residence'] = \"NA\"\n",
        "            # d['current_residence'] = \"NA\"\n",
        "            # d['original_speaker_id'] = d_sentence[n]\n",
        "            speaker_list2.append(d)     \n",
        "  # 그다음꺼 있으면    2  \n",
        "    if d_end != False:\n",
        "      for h in range(len(s_sentence)):\n",
        "        if h > d_end:\n",
        "          if s_sentence[d_end] ==\"\" and s_sentence[d_end+1] ==\"\" and not s_sentence[d_end+2].startswith(\"◯\"):          \n",
        "            part3 = d_end +2\n",
        "            e_part = s_sentence[part3]        \n",
        "            break\n",
        "      # print(part2)\n",
        "      if part3 != False:\n",
        "        for r in range(len(s_sentence)):\n",
        "          if r >= part3:\n",
        "            if s_sentence[r] == \"\" and s_sentence[r+1] ==\"\":\n",
        "              e_end = r        \n",
        "              break\n",
        "            else:\n",
        "              e_end = r + 1\n",
        "      if part3 != False:\n",
        "        for m in range(len(s_sentence)):\n",
        "          if m >= part3 and m < e_end:\n",
        "            ssssss = s_sentence[m].split('\\n')      \n",
        "            e_sentence += ssssss\n",
        "        # pprint(d_sentence)\n",
        "        count = int((len(e_sentence) -1) / 2) + 1  \n",
        "        id_e = range(count, len(e_sentence))\n",
        "        ocu_e = range(1,count)\n",
        "        for n, m in zip(id_e, ocu_e) :                \n",
        "          if e_sentence[n] not in p_name:        \n",
        "            d = {}\n",
        "            d['id'] = e_sentence[n]\n",
        "            # d['age'] = \"NA\"\n",
        "            d['occupation'] = e_part + e_sentence[m]\n",
        "            # d['sex'] = \"NA\"\n",
        "            # d['birthplace'] = \"NA\"\n",
        "            # d['principal_residence'] = \"NA\"\n",
        "            # d['current_residence'] = \"NA\"\n",
        "            # d['original_speaker_id'] = e_sentence[n]\n",
        "            speaker_list2.append(d)\n",
        "  # 그다음꺼 있으면   3\n",
        "    if e_end != False:\n",
        "      for h in range(len(s_sentence)):\n",
        "        if h > e_end:\n",
        "          if s_sentence[e_end] ==\"\" and s_sentence[e_end+1] ==\"\" and not s_sentence[e_end+2].startswith(\"◯\"):          \n",
        "            part4 = e_end +2\n",
        "            f_part = s_sentence[part4]        \n",
        "            break\n",
        "      # print(part2)\n",
        "      if part4 != False:\n",
        "        for r in range(len(s_sentence)):\n",
        "          if r >= part4:\n",
        "            if s_sentence[r] == \"\" and s_sentence[r+1] ==\"\":\n",
        "              f_end = r        \n",
        "              break\n",
        "            else:\n",
        "              f_end = r + 1\n",
        "      if part4 != False:\n",
        "        for m in range(len(s_sentence)):\n",
        "          if m >= part4 and m < f_end:\n",
        "            sssssss = s_sentence[m].split('\\n')      \n",
        "            f_sentence += sssssss\n",
        "        # pprint(d_sentence)\n",
        "        count = int((len(f_sentence) -1) / 2) + 1  \n",
        "        id_f = range(count, len(f_sentence))\n",
        "        ocu_f = range(1,count)\n",
        "        for n, m in zip(id_f, ocu_f) :                \n",
        "          if f_sentence[n] not in p_name:        \n",
        "            d = {}\n",
        "            d['id'] = f_sentence[n]\n",
        "            # d['age'] = \"NA\"\n",
        "            d['occupation'] = f_part + f_sentence[m]\n",
        "            # d['sex'] = \"NA\"\n",
        "            # d['birthplace'] = \"NA\"\n",
        "            # d['principal_residence'] = \"NA\"\n",
        "            # d['current_residence'] = \"NA\"\n",
        "            # d['original_speaker_id'] = f_sentence[n]\n",
        "            speaker_list2.append(d)\n",
        "  # 그다음꺼 있으면 4\n",
        "    if f_end != False:\n",
        "      for h in range(len(s_sentence)):\n",
        "        if h > f_end:\n",
        "          if s_sentence[f_end] ==\"\" and s_sentence[f_end+1] ==\"\" and not s_sentence[f_end+2].startswith(\"◯\"):          \n",
        "            part5 = f_end +2\n",
        "            g_part = s_sentence[part5]        \n",
        "            break      \n",
        "      if part5 != False:\n",
        "        for r in range(len(s_sentence)):\n",
        "          if r >= part5:\n",
        "            if s_sentence[r] == \"\" and s_sentence[r+1] ==\"\":\n",
        "              g_end = r        \n",
        "              break\n",
        "            else:\n",
        "              g_end = r + 1\n",
        "      if part5 != False:\n",
        "        for m in range(len(s_sentence)):\n",
        "          if m >= part5 and m < g_end:\n",
        "            ssssssss = s_sentence[m].split('\\n')      \n",
        "            g_sentence += ssssssss\n",
        "        # pprint(d_sentence)\n",
        "        count = int((len(f_sentence) -1) / 2) + 1  \n",
        "        id_g = range(count, len(f_sentence))\n",
        "        ocu_g = range(1,count)\n",
        "        for n, m in zip(id_g, ocu_g) :                \n",
        "          if g_sentence[n] not in p_name:        \n",
        "            d = {}\n",
        "            d['id'] = g_sentence[n]\n",
        "            # d['age'] = \"NA\"\n",
        "            d['occupation'] = g_part + g_sentence[m]\n",
        "            # d['sex'] = \"NA\"\n",
        "            # d['birthplace'] = \"NA\"\n",
        "            # d['principal_residence'] = \"NA\"\n",
        "            # d['current_residence'] = \"NA\"\n",
        "            # d['original_speaker_id'] = f_sentence[n]\n",
        "            speaker_list2.append(d)              \n",
        "      # print(\"except\")\n",
        "    # 진술인 참고인 \n",
        "    for f in range(len(s_sentence)):\n",
        "      if s_sentence[f].startswith(\"◯\") and (s_sentence[f].endswith(\"참고인\") or s_sentence[f].endswith(\"진술인\")):\n",
        "        ss_start = f + 1\n",
        "        for jin in range(len(s_sentence)):\n",
        "          if jin >= ss_start:            \n",
        "            ro = ''.join(s_sentence[jin][0:-1].split(\"(\",1)[1:2]).split(\" \")                        \n",
        "            rol = ''.join(ro).split('\\n')\n",
        "            role += rol   \n",
        "\n",
        "    if ss_start != False:      \n",
        "      for j in range(len(s_sentence)):        \n",
        "        if j >= ss_start:\n",
        "          ee = s_sentence[j].split(\"(\")\n",
        "          eee = ee[0].split('\\n')\n",
        "          e_sentence += eee    \n",
        "      for n in range(len(e_sentence)) :                \n",
        "        if e_sentence[n] not in p_name:        \n",
        "          d = {}\n",
        "          d['id'] = e_sentence[n]\n",
        "          # d['age'] = \"NA\"\n",
        "          d['occupation'] = role[n]\n",
        "          # d['sex'] = \"NA\"\n",
        "          # d['birthplace'] = \"NA\"\n",
        "          # d['principal_residence'] = \"NA\"\n",
        "          # d['current_residence'] = \"NA\"\n",
        "          # d['original_speaker_id'] = e_sentence[n]\n",
        "          speaker_list2.append(d)    \n",
        "    # print(p_name)    \n",
        "  except:\n",
        "    print(\"except\")\n",
        "    # 진술인 참고인\n",
        "  \n",
        "    for f in range(len(s_sentence)):\n",
        "      if s_sentence[f].startswith(\"◯\") and (s_sentence[f].endswith(\"참고인\") or s_sentence[f].endswith(\"진술인\")):\n",
        "        ss_start = f + 1\n",
        "        for jin in range(len(s_sentence)):\n",
        "          if jin >= ss_start:            \n",
        "            ro = ''.join(s_sentence[jin][0:-1].split(\"(\",1)[1:2]).split(\" \")\n",
        "            rol = ''.join(ro).split('\\n')\n",
        "            role += rol   \n",
        "\n",
        "    if ss_start != False:      \n",
        "      for j in range(len(s_sentence)):        \n",
        "        if j >= ss_start:\n",
        "          ee = s_sentence[j].split(\"(\")\n",
        "          eee = ee[0].split('\\n')\n",
        "          e_sentence += eee    \n",
        "      for n in range(len(e_sentence)) :                \n",
        "        if e_sentence[n] not in p_name:        \n",
        "          d = {}\n",
        "          d['id'] = e_sentence[n]\n",
        "          # d['age'] = \"NA\"\n",
        "          d['occupation'] = role[n]\n",
        "          # d['sex'] = \"NA\"\n",
        "          # d['birthplace'] = \"NA\"\n",
        "          # d['principal_residence'] = \"NA\"\n",
        "          # d['current_residence'] = \"NA\"\n",
        "          # d['original_speaker_id'] = e_sentence[n]\n",
        "          speaker_list2.append(d)    \n",
        "    # print(p_name)    \n",
        "  finally:\n",
        "    for last in range(len(speaker_list2)):\n",
        "      if speaker_list2[last]['id'] not in p2_name:\n",
        "        d = {}\n",
        "        d['id'] = speaker_list2[last]['id']\n",
        "        # d['age'] = \"NA\"\n",
        "        d['occupation'] = speaker_list2[last]['occupation']\n",
        "        # d['sex'] = \"NA\"\n",
        "        # d['birthplace'] = \"NA\"\n",
        "        # d['principal_residence'] = \"NA\"\n",
        "        # d['current_residence'] = \"NA\"\n",
        "        # d['original_speaker_id'] = speaker_list2[last]['id']  \n",
        "        speaker_list2__2.append(d)     \n",
        "  return speaker_list2__2\n",
        "speaker_list2__2 = speaker_extractor2_or(text,speaker_list, speaker_list__, speaker_ex)\n",
        "# pprint(speaker_list2__2)"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8txKx-PLc48"
      },
      "source": [
        "# json 형태로 변환하기 위한 틀\n",
        "def convert_to_korea(meta, speaker_list, speaker_list__, speaker_list2__2, dialog_json, id):\n",
        "    # k = 0\n",
        "    id = \"SBRW 2100000001\"\n",
        "    # id_code = korea_formatted_data['id']\n",
        "    # id = id_code.split(\" \")\n",
        "    # id0 = id[0]\n",
        "    # id1 = int(id[1]) + k\n",
        "    # id = id0 + str(id1)\n",
        "    # korea_formatted_data['id'] = id    \n",
        "    # k += 1\n",
        "\n",
        "    metadata = {}\n",
        "    metadata['title'] = \"국립국어원 국회 회의록 원시 말뭉치 \" + id\n",
        "    metadata['creator'] = \"국립국어원\"\n",
        "    metadata['distributor'] = \"국립국어원\"\n",
        "    metadata['year'] = \"2021\"\n",
        "    metadata['category'] = meta['카테고리']\n",
        "    metadata['annotation_level'] = ['원시']\n",
        "    metadata['sampling'] = \"본문 전체\"\n",
        "        \n",
        "    doc = {}\n",
        "    doc['id'] = id+\".1\"\n",
        "    doc_metadata = {}\n",
        "    doc_metadata['title'] = meta['회의록제목']\n",
        "    doc_metadata['author'] = meta['작성']\n",
        "    # doc_metadata['author_id'] = \"\" \n",
        "    doc_metadata['publisher'] = meta['작성']\n",
        "    doc_metadata['date'] = meta['일시']\n",
        "    doc_metadata['topic'] = meta['토픽']    \n",
        "    # doc_metadata['original_topic'] = \"\"\n",
        "    # doc_metadata['crawl_date'] = \"\"\n",
        "\n",
        "    doc_metadata['speaker'] = speaker_list__ + speaker_list2__2    \n",
        "    # pprint(meta['회의록제목'])\n",
        "    # pprint(meta['일시'])\n",
        "    # pprint(doc_metadata['speaker'])\n",
        "    # doc_metadata['setting'] = {}\n",
        "    # doc_metadata['setting']['relation'] = \"NA\"\n",
        "    \n",
        "    # doc_metadata['file_id'] = meta['파일명']\n",
        "      # '회의록 원문 자료 파일명:'\n",
        "\n",
        "    doc['metadata'] = doc_metadata\n",
        "    \n",
        "    # doc['paragraph'] = []\n",
        "    # paragraph = {}\n",
        "    # paragraph['id'] = \"\"\n",
        "    # paragraph['form'] = \"\"\n",
        "    # paragraph['original_form'] = \"\"\n",
        "    # doc['paragraph'].append(paragraph)\n",
        "    \n",
        "    utterance = []\n",
        "    \n",
        "    n = 0\n",
        "    for i in dialog_json:\n",
        "        utter = {}\n",
        "        utter['id'] = id+\".1.1.\"+ str(n+1)\n",
        "        utter['form'] = i['utterance']\n",
        "        utter['original_form'] = i['utterance_or']\n",
        "        utter['speaker_id'] = i['speaker']\n",
        "        utter['note'] = i['note']\n",
        "        utterance.append(utter)\n",
        "        n += 1\n",
        "        # pprint(utter['id'])   \n",
        "    doc['utterance'] = utterance\n",
        "    \n",
        "    d = {}\n",
        "    d['id'] = id\n",
        "    d['metadata'] = metadata\n",
        "    d['document'] = doc\n",
        "    \n",
        "    return d\n",
        "korea_formatted_data = convert_to_korea(meta, speaker_list,speaker_list__, speaker_list2__2, dialog_json, id)\n",
        "# pprint(korea_formatted_data)\n",
        "# pprint(korea_formatted_data['document']['utterance'][0])"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-FFM7qP3jj7",
        "outputId": "af0c98f2-2933-4585-8bb1-a81c95daf32e"
      },
      "source": [
        "# json 형태로 변환\n",
        "def txt_reader(id):\n",
        "  k = 0\n",
        "  files = sorted(glob('/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/*.txt'))  \n",
        "  for fname in files:\n",
        "    with open(fname, 'r', encoding='utf-8-sig') as file:\n",
        "      txt = file.readlines()      \n",
        "      pass\n",
        "      text = clean_up(txt)            \n",
        "      pm_date = date_extractor(text)      \n",
        "      pm_author = author(text)      \n",
        "      pm_topic = topic_extractor(text)      \n",
        "      meta = meta_extractor(text, pm_date, pm_topic, pm_author, fname)      \n",
        "      dialog = dialog_extractor(txt)      \n",
        "      dialog_or = dialog_extractor_or(txt)\n",
        "      speaker_ex = speaker_extractor(dialog)\n",
        "      speaker_ex_or = speaker_extractor_or(dialog_or)      \n",
        "      utterance_ex = utterance_extractor(dialog)       \n",
        "      utterance_ex_or = utterance_extractor_or(dialog_or)         \n",
        "      dialog_json = dialog_formatting(utterance_ex, utterance_ex_or)  \n",
        "      speaker_list = speaker_list_extractor(speaker_ex,speaker_ex_or)              \n",
        "      speaker_list__ = speaker_list_extractor_or(speaker_ex,speaker_ex_or)      \n",
        "      speaker_list2__2 = speaker_extractor2_or(text,speaker_list, speaker_list__, speaker_ex)     \n",
        "      korea_formatted_data = convert_to_korea(meta, speaker_list, speaker_list__, speaker_list2__2, dialog_json, id)     \n",
        "      id = \"SBRW 2100000001\"\n",
        "      id_code = id.split(\" \")\n",
        "      id0 = id_code[0]\n",
        "      id1 = int(id_code[1]) + k\n",
        "      id_code = id0 + str(id1)\n",
        "      korea_formatted_data['id'] = id_code\n",
        "      korea_formatted_data['metadata']['title'] = \"국립국어원 국회 회의록 원시 말뭉치 \" + id_code\n",
        "      korea_formatted_data['document']['id'] = id_code + \".1\"\n",
        "      # print(korea_formatted_data)\n",
        "      n = 0\n",
        "      for i in dialog_json:\n",
        "        korea_formatted_data['document']['utterance'][n]['id'] = id_code+\".1.1.\"+ str(n+1)\n",
        "        n += 1\n",
        "      k += 1     \n",
        "    # fname_write = fname.split('/')[-1].split('.txt')[0]    \n",
        "      \n",
        "    with open('/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차 json/'+id_code+'.json', 'w') as f:\n",
        "      json.dump(korea_formatted_data, f, ensure_ascii=False, indent=4)\n",
        "    \n",
        "    # /content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/(jw)pm_summary_preprocessor/\n",
        "\n",
        "txt_reader(id)\n",
        "# txt_reader(fname)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "except\n",
            "except\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x8grIgmYE87"
      },
      "source": [
        "def mapping_table(map,utterance_ex):      \n",
        "  k = 0  \n",
        "  files = sorted(glob('/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/회의록 2차/*.txt'))  \n",
        "  for fname in files:\n",
        "    with open(fname, 'r', encoding='utf-8-sig') as file:\n",
        "      txt = file.readlines()\n",
        "      pass              \n",
        "      map = mapping(txt)\n",
        "      dialog = dialog_extractor(txt)\n",
        "      utterance_ex = utterance_extractor(dialog)\n",
        "      id = \"SBRW 2100000001\"\n",
        "      id_code = id.split(\" \")\n",
        "      id0 = id_code[0]\n",
        "      id1 = int(id_code[1]) + k\n",
        "      id_code = id0 + str(id1)\n",
        "      o_id = []    \n",
        "      n_id = []  \n",
        "      o_id = map[0]\n",
        "      n_id = map[1]\n",
        "      o_utter = map[2]\n",
        "      n_utter = map[3]      \n",
        "      mapp = []\n",
        "      mappp = []\n",
        "      speaker = utterance_ex[1]\n",
        "      utterance = utterance_ex[2]        \n",
        "\n",
        "      # if n_utter in o_utter:\n",
        "      #   pass\n",
        "      # else:\n",
        "      #   print(k)\n",
        "      #   print('error')\n",
        "      \n",
        "      for m in range(len(n_id)):\n",
        "        o_id = [map[0][m]]\n",
        "        n_id = [map[1][m]]\n",
        "        speaker = [utterance_ex[1][m]]\n",
        "        utterance = [utterance_ex[2][m]]\n",
        "        mapp = n_id + o_id + speaker + utterance\n",
        "        mappp.append(mapp)            \n",
        "  \n",
        "    with open(\"/content/drive/My Drive/Colab Notebooks/task/Minutes(Korean)/mapping_table 2차/\"+ id_code+\".csv\", 'wt', encoding='utf-8-sig', newline='') as out_file:      \n",
        "      csv_writer = csv.writer(out_file, delimiter=',') \n",
        "      csv_writer.writerow([\"new_id\",\"ori_id\",\"speaker\",\"utterance\"])\n",
        "      csv_writer.writerows(mappp)\n",
        "      k +=1\n",
        "\n",
        "      \n",
        "mapping_table(map,utterance_ex)\n",
        "#   return mapp\n",
        "# mapping_table = mapping_table(utterance_ex,mapping)\n",
        "# pprint(mapping_table)"
      ],
      "execution_count": 173,
      "outputs": []
    }
  ]
}